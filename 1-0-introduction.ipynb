{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Goal of this course: learn how to program GPUs with Julia\n",
    "\n",
    "Expected experience: minimal familiarity with Julia and GPU programming\n",
    "\n",
    "Day 1: programming the GPU\n",
    "- Introduction\n",
    "- Programming models\n",
    "- Profiling and optimization\n",
    "\n",
    "Day 2: advanced topics\n",
    "- Memory management\n",
    "- Concurrent computing\n",
    "- Low-level CUDA APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why GPU programming in Julia?\n",
    "\n",
    "*Very briefly*: Julia is\n",
    "\n",
    "- a **high level** language: easy to write and read\n",
    "- **designed for performance**: by using careful abstractions, and a JIT compiler\n",
    "\n",
    "This relatively unique combination makes it a great language for GPU programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why CUDA.jl?\n",
    "\n",
    "Essentially, because it's the most mature and best optimized GPU back-end for Julia.\n",
    "\n",
    "However, other back-ends are built on top of the same stack, and share a lot of the same infrastructure:\n",
    "\n",
    "- GPUArrays.jl: vendor neutral array operations\n",
    "- GPUCompiler.jl: shared infrastructure for kernel compilation\n",
    "- LLVM.jl, Adapt.jl, etc\n",
    "\n",
    "As a result, it should be possible to apply much of what you learn here to other back-ends as well. In order of maturity:\n",
    "\n",
    "- AMDGPU.jl: for [ROCM-supported](https://rocm.docs.amd.com/en/latest/release/gpu_os_support.html) GPUs on Linux\n",
    "- oneAPI.jl: for most [Intel IGPs and dedicated GPUs](https://github.com/intel/compute-runtime#supported-platforms) on Linux\n",
    "- Metal.jl: for Apple M-series GPUs on macOS\n",
    "\n",
    "There's some other experimental back-ends; for more details, see [juliagpu.org](https://juliagpu.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "CUDA.jl is easy to install, just do `Pkg.add(\"CUDA\")`. For this course, I've provided a pre-configured environment with all relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/course`\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe active manifest file has dependencies that were resolved with a different julia version (1.9.3). Unexpected behavior may occur.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ ~/course/Manifest.toml:0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSIMDTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mUnPack\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRealDot\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCustomUnitRanges\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRangeArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mManualMemory\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIndirectArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTensorCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsAPI\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIntervalSets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPkgVersion\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIterTools\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDocStringExtensions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRatios\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIfElse\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mProgressMeter\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNaNMath\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLazyModules\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInflate\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIrrationalConstants\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mComputationalResources\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCpuId\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMappedArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTranscodingStreams\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSuiteSparse\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWoodburyMatrices\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSimpleTraits\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLERC_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIntelOpenMP_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImath_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibpng_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJpegTurbo_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mZstd_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mParameters\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mQuaternions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIntervalSets → IntervalSetsStatisticsExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCoordinateTransformations\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRecipesBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRatios → RatiosFixedPointNumbersExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArnoldiMethod\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mThreadingUtilities\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRegionTrees\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatic\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphics\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistances\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOffsetArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTranscodingStreams → TestExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mAxisAlgorithms\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs → AbstractFFTsChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMKL_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenEXR_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore → ChainRulesCoreSparseArraysExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibsixel_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFileIO\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBitTwiddlingConvenienceFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIntegralArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLibtiff_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mAxisArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesSparseArraysExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCatIndices\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStackViews\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPaddedViews\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceGPUArraysCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCPUSummary\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorVectorSpace\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions → LogExpFunctionsChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs → AbstractFFTsTestExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRotations\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mQOI\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMosaicViews\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHostCPUFeatures\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenEXR\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPolyesterWeave\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceStaticArraysCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageMagick_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStringDistances\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorVectorSpace → SpecialFunctionsExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGraphs\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions → SpecialFunctionsChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mClustering\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDiffRules\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSimpleWeightedGraphs\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTViews\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorSchemes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mTullio\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTullio → TullioChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPolynomials\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPolynomials → PolynomialsChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJLD2\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMetaGraphs\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJpegTurbo\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSixel\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPNGFiles\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageMagick\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHistogramThresholding\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageTransformations\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageShow\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageAxes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageBinarization\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageMetadata\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageContrastAdjustment\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTiffImages\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNetpbm\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mImageIO\n",
      "\u001b[32m  ✓ \u001b[39mTestImages\n",
      "\u001b[32m  ✓ \u001b[39mCUDA\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceCUDAExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTullio → TullioCUDAExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA → SpecialFunctionsExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceStaticArraysExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceOffsetArraysExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCloseOpenIntervals\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA → ChainRulesCoreExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mTiledIteration\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLayoutPointers\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mVectorizationBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSLEEFPirates\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLoopVectorization\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLoopVectorization → SpecialFunctionsExt\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageMorphology\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageDistances\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageFiltering\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageSegmentation\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageCorners\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageQualityIndexes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mImages\n",
      "  141 dependencies successfully precompiled in 121 seconds. 72 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, try `CUDA.versioninfo()` to see some details about the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling CUDA [052768ef-5323-5732-b1bb-66c8b64840ba]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA runtime 12.3, artifact installation\n",
      "CUDA driver 12.3\n",
      "NVIDIA driver 470.57.2, originally for CUDA 11.4\n",
      "\n",
      "CUDA libraries: \n",
      "- CUBLAS: 12.3.2\n",
      "- CURAND: 10.3.4\n",
      "- CUFFT: 11.0.11\n",
      "- CUSOLVER: 11.5.3\n",
      "- CUSPARSE: 12.1.3\n",
      "- CUPTI: 21.0.0\n",
      "- NVML: 11.0.0+470.57.2\n",
      "\n",
      "Julia packages: \n",
      "- CUDA: 5.1.0\n",
      "- CUDA_Driver_jll: 0.7.0+0\n",
      "- CUDA_Runtime_jll: 0.10.0+1\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.10.0-rc1\n",
      "- LLVM: 15.0.7\n",
      "\n",
      "Environment:\n",
      "- JULIA_CUDA_MEMORY_POOL: none\n",
      "\n",
      "1 device:\n",
      "  0: Tesla P100-PCIE-16GB (sm_60, 15.897 GiB / 15.899 GiB available)\n"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "CUDA.versioninfo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA.jl bundles many CUDA libraries (from the core toolkit as well as external libraries), making them available as artifacts packaged using BinaryBuilder.jl. Selection of these libraries is tricky, as several compatibility requirements need to be taken into account:\n",
    "\n",
    "- the local NVIDIA driver has a CUDA Toolkit compatibility level\n",
    "- starting with CUDA 11.0, the driver is forwards-compatible (\"Enhanced Compatibility\")\n",
    "- it may be possible to load a more recent driver library to raise the compatibility level (\"Forward Compatibility\")\n",
    "- external libraries (CUDNN, CUTENSOR) may have builds for each CUDA Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this course, this should be using CUDA 12.3 from artifacts (instead of the old CUDA 11.0 toolkit provided by the module system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would need to disable use of artifacts, call `CUDA.set_runtime_version!(version; local_toolkit=true)` where `version` is the version of the local CUDA toolkit. In this configuration, you are responsible for ensuring compatibility between the driver, toolkit, and any libraries! `CUDA.versioninfo()` will then look as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia-repl\n",
    "julia> CUDA.versioninfo()\n",
    "CUDA toolkit 11.4, local installation\n",
    "NVIDIA driver 470.74.0, for CUDA 11.4\n",
    "CUDA driver 11.4\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CUDA.jl doesn't manage to discover your local CUDA installation, you can try launching Julia with the environment variable `JULIA_DEBUG` set to `CUDA`. This will reveal the locations CUDA.jl searches in for toolkit libraries and binaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ JULIA_DEBUG=CUDA \\\n",
    "  julia -e 'using CUDA; device()\n",
    "┌ Debug: Trying to use local installation...\n",
    "└ @ CUDA.Deps ~/.julia/packages/CUDA/YpW0k/deps/bindeps.jl:164\n",
    "┌ Debug: Looking for CUDA toolkit via environment variables CUDA_PATH\n",
    "└ @ CUDA.Deps ~/.julia/packages/CUDA/YpW0k/deps/discovery.jl:271\n",
    "┌ Debug: Looking for binary nvdisasm in /opt/cuda\n",
    "│   all_locations =\n",
    "│    2-element Vector{String}:\n",
    "│     \"/opt/cuda\"\n",
    "│     \"/opt/cuda/bin\"\n",
    "└ @ CUDA.Deps ~/.julia/packages/CUDA/YpW0k/deps/discovery.jl:147\n",
    "┌ Debug: Found nvdisasm at /opt/cuda/bin/nvdisasm\n",
    "└ @ CUDA.Deps ~/.julia/packages/CUDA/YpW0k/deps/discovery.jl:153\n",
    "┌ Debug: Looking for library cudart, no specific version, in /opt/cuda\n",
    "...\n",
    "└ @ CUDA.Deps ~/.julia/packages/CUDA/YpW0k/deps/compatibility.jl:210\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick tour\n",
    "\n",
    "CUDA.jl is a large package, containing a lot of functionality:\n",
    "\n",
    "- wrappers for the CUDA driver, to manage devices, streams, etc\n",
    "- wrappers for CUDA's libraries, such as cuBLAS, cuFFT, cuRAND, etc\n",
    "- native kernel programming support: `@cuda`, intrinsics wrappers, a compiler, etc\n",
    "- high-level functionality that builds on all of the above: `CuArray`, array operations, stdlib integrations, etc\n",
    "\n",
    "As an introduction, I'll use a simple parallel operation that can be used to demonstrate all of the above: AXPY, or $z = \\alpha x + y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple CPU implementation of AXPY using array operations would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Int64}:\n",
       "  6\n",
       " 11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axpy!(z, a, x, y) = z .= a .* x .+ y\n",
    "\n",
    "x = [1, 2]\n",
    "y = [2, 3]\n",
    "alpha = 4\n",
    "z = similar(x)\n",
    "\n",
    "axpy!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the highest level of abstraction, we can use exactly the same array operations with CUDA.jl to run this on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       "  6\n",
       " 11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CuArray([1, 2])\n",
    "y = CuArray([2, 3])\n",
    "alpha = 4\n",
    "z = similar(x)\n",
    "\n",
    "axpy!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the strenghts of Julia's GPU ecosystem: Generic array operations make it possible to write code that works on all kinds of inputs. Just changing the input type is sufficient to \"port\" an application to the GPU. Of course, this doesn't always work out perfectly, and sometimes you still need custom operations, but it's a great starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peel back one of the layers, and implement a custom kernel instead of re-using the `broadcast` implementation from CUDA.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       "  6\n",
       " 11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function axpy_kernel!(z, a, x, y)\n",
    "    function kernel(z, a, x, y)\n",
    "        i = threadIdx().x\n",
    "        if i ≤ length(z)\n",
    "            @inbounds z[i] = a * x[i] + y[i]\n",
    "        end\n",
    "        return\n",
    "    end\n",
    "\n",
    "    @cuda threads=length(z) kernel(z, a, x, y)\n",
    "\n",
    "    return z\n",
    "end\n",
    "\n",
    "x = CuArray([1, 2])\n",
    "y = CuArray([2, 3])\n",
    "alpha = 4\n",
    "z = similar(x)\n",
    "axpy_kernel!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel above is too simple though, as it ignores a crucial limitation: you cannot launch an unbounded number of threads, but need to respect the device limit and, if needed, launch multiple blocks. Let's use at most 256 threads, which should work on any GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       "  6\n",
       " 11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function axpy_kernel!(z, a, x, y)\n",
    "    function kernel(z, a, x, y)\n",
    "        i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "        if i ≤ length(z)\n",
    "            @inbounds z[i] = a * x[i] + y[i]\n",
    "        end\n",
    "        return\n",
    "    end\n",
    "\n",
    "    kernel = @cuda launch=false kernel(z, a, x, y)\n",
    "    threads = min(length(z), 256)\n",
    "    blocks = cld(length(z), threads)\n",
    "    kernel(z, a, x, y; threads, blocks)\n",
    "\n",
    "    return z\n",
    "end\n",
    "\n",
    "x = CuArray([1, 2])\n",
    "y = CuArray([2, 3])\n",
    "alpha = 4\n",
    "z = similar(x)\n",
    "axpy_kernel!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, there's already a good reason to use this `saxpy_kernel!` version, as it's generates slightly better code (requiring fewer registers) than the fully generic `broadcast` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 460.15 µs, capturing 4 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 46.97 µs (10.21% of the trace)\n",
       "┌────┬──────────┬──────────┬────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m    Start \u001b[0m│\u001b[1m     Time \u001b[0m│\u001b[1m Name           \u001b[0m│\n",
       "├────┼──────────┼──────────┼────────────────┤\n",
       "│  2 │ 51.26 µs │\u001b[31m 46.73 µs \u001b[0m│\u001b[1m cuLaunchKernel \u001b[0m│\n",
       "└────┴──────────┴──────────┴────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 366.45 µs (79.64% of the trace)\n",
       "┌────┬──────────┬───────────┬─────────┬────────┬──────┬─────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m    Start \u001b[0m│\u001b[1m      Time \u001b[0m│\u001b[1m Threads \u001b[0m│\u001b[1m Blocks \u001b[0m│\u001b[1m Regs \u001b[0m│\u001b[1m Name                                                                        \u001b[0m│\n",
       "├────┼──────────┼───────────┼─────────┼────────┼──────┼─────────────────────────────────────────────────────────────────────────────┤\n",
       "│  2 │ 91.79 µs │\u001b[31m 366.45 µs \u001b[0m│     256 │  65536 │    8 │\u001b[1m _Z6kernel13CuDeviceArrayI7Float32Li2ELi1EES0_S_IS0_Li2ELi1EES_IS0_Li2ELi1EE \u001b[0m│\n",
       "└────┴──────────┴───────────┴─────────┴────────┴──────┴─────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CUDA.rand(Float32, 4096, 4096)\n",
    "y = CUDA.rand(Float32, 4096, 4096)\n",
    "z = similar(x)\n",
    "alpha = rand(Float32)\n",
    "axpy_kernel!(z, alpha, x, y)   # warm-up\n",
    "CUDA.@profile trace=true axpy_kernel!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 650.17 µs, capturing 6 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 33.86 µs (5.21% of the trace)\n",
       "┌────┬─────────┬──────────┬────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m   Start \u001b[0m│\u001b[1m     Time \u001b[0m│\u001b[1m Name           \u001b[0m│\n",
       "├────┼─────────┼──────────┼────────────────┤\n",
       "│  4 │ 65.8 µs │\u001b[31m 31.23 µs \u001b[0m│\u001b[1m cuLaunchKernel \u001b[0m│\n",
       "└────┴─────────┴──────────┴────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 554.8 µs (85.33% of the trace)\n",
       "┌────┬──────────┬──────────┬─────────┬────────┬──────┬───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m    Start \u001b[0m│\u001b[1m     Time \u001b[0m│\u001b[1m Threads \u001b[0m│\u001b[1m Blocks \u001b[0m│\u001b[1m Regs \u001b[0m│\u001b[1m Name                                                                                                                                                                                                                                                                      \u001b[0m│\n",
       "├────┼──────────┼──────────┼─────────┼────────┼──────┼───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│  4 │ 92.98 µs │\u001b[31m 554.8 µs \u001b[0m│    1024 │    112 │   32 │\u001b[1m _Z16broadcast_kernel15CuKernelContext13CuDeviceArrayI7Float32Li2ELi1EE11BroadcastedI12CuArrayStyleILi2EE5TupleI5OneToI5Int64ES5_IS6_EE1_S4_IS2_IS3_ILi2EEvS7_S4_IS1_8ExtrudedIS0_IS1_Li2ELi1EES4_I4BoolS9_ES4_IS6_S6_EEEES8_IS0_IS1_Li2ELi1EES4_IS9_S9_ES4_IS6_S6_EEEES6_ \u001b[0m│\n",
       "└────┴──────────┴──────────┴─────────┴────────┴──────┴───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axpy!(z, alpha, x, y)\n",
    "CUDA.@profile trace=true axpy!(z, alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to compute AXPY is to use the cuBLAS library, which provides the `cublasXaxpy` functions. We've got those conveniently wrapped in CUDA.jl as `CUBLAS.axpy!`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching axpy!(::Int64, ::Int64, ::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}, ::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{ComplexF16}\u001b[39m, \u001b[91m::StridedCuArray{ComplexF16}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:226\u001b[24m\u001b[39m\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{Float16}\u001b[39m, \u001b[91m::StridedCuArray{Float16}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:221\u001b[24m\u001b[39m\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{ComplexF32}\u001b[39m, \u001b[91m::StridedCuArray{ComplexF32}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:211\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching axpy!(::Int64, ::Int64, ::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}, ::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{ComplexF16}\u001b[39m, \u001b[91m::StridedCuArray{ComplexF16}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:226\u001b[24m\u001b[39m\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{Float16}\u001b[39m, \u001b[91m::StridedCuArray{Float16}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:221\u001b[24m\u001b[39m\n\u001b[0m  axpy!(::Integer, ::Number, \u001b[91m::StridedCuArray{ComplexF32}\u001b[39m, \u001b[91m::StridedCuArray{ComplexF32}\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mCUDA\u001b[39m \u001b[90m~/CUDA/lib/cublas/\u001b[39m\u001b[90m\u001b[4mwrappers.jl:211\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[9]:4"
     ]
    }
   ],
   "source": [
    "x = CuArray([1, 2])\n",
    "y = CuArray([2, 3])\n",
    "alpha = 4\n",
    "CUBLAS.axpy!(length(y), alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that immediately demonstrates one of the limitations of NVIDIA's vendor libraries: they only support a handful of types. This is one of the reasons that a native compiler is so valuable.\n",
    "\n",
    "To test CUBLAS, let's use Float32 inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       "  6.0\n",
       " 11.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CuArray([1f0, 2f0])\n",
    "y = CuArray([2f0, 3f0])\n",
    "alpha = 4f0\n",
    "CUBLAS.axpy!(length(y), alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profiler ran for 467.3 µs, capturing 6 events.\n",
       "\n",
       "Host-side activity: calling CUDA APIs took 30.04 µs (6.43% of the trace)\n",
       "┌────┬──────────┬───────────┬──────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m    Start \u001b[0m│\u001b[1m      Time \u001b[0m│\u001b[1m Name             \u001b[0m│\n",
       "├────┼──────────┼───────────┼──────────────────┤\n",
       "│  2 │ 14.78 µs │ 715.26 ns │ cudaGetLastError │\n",
       "│  3 │ 18.12 µs │\u001b[31m  28.61 µs \u001b[0m│\u001b[1m cudaLaunchKernel \u001b[0m│\n",
       "│  4 │ 46.97 µs │    0.0 ns │ cudaGetLastError │\n",
       "└────┴──────────┴───────────┴──────────────────┘\n",
       "\n",
       "Device-side activity: GPU was busy for 420.57 µs (90.00% of the trace)\n",
       "┌────┬──────────┬───────────┬─────────┬────────┬──────┬─────────────────────────────────────────────────────────┐\n",
       "│\u001b[1m ID \u001b[0m│\u001b[1m    Start \u001b[0m│\u001b[1m      Time \u001b[0m│\u001b[1m Threads \u001b[0m│\u001b[1m Blocks \u001b[0m│\u001b[1m Regs \u001b[0m│\u001b[1m Name                                                    \u001b[0m│\n",
       "├────┼──────────┼───────────┼─────────┼────────┼──────┼─────────────────────────────────────────────────────────┤\n",
       "│  3 │ 44.58 µs │\u001b[31m 420.57 µs \u001b[0m│     256 │  65536 │   32 │\u001b[1m _Z15axpy_kernel_valIffEv19cublasAxpyParamsValIT_S1_T0_E \u001b[0m│\n",
       "└────┴──────────┴───────────┴─────────┴────────┴──────┴─────────────────────────────────────────────────────────┘\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CUDA.rand(Float32, 4096, 4096)\n",
    "y = CUDA.rand(Float32, 4096, 4096)\n",
    "alpha = rand(Float32)\n",
    "CUBLAS.axpy!(length(y), alpha, x, y)   # warm-up\n",
    "CUDA.@profile trace=true CUBLAS.axpy!(length(y), alpha, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that despite using the most registers, CUBLAS is faster than both our naive `axpy!` kernel, and the `broadcast` implementation. That's not unexpected, but at the same time, the difference isn't huge either, so it's always a good thing to benchmark your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, before moving on to the next notebook, be sure to stop or restart the kernel, as Piz Daint only allows a single process to use the GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0-rc1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
